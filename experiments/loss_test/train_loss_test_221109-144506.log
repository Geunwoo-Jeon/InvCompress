22-11-09 14:45:17.051 - INFO: Munch({'quan': Munch({'act': Munch({'mode': 'lsq_qel_act', 'bit': 8, 'per_channel': False, 'symmetric': False, 'all_positive': True}), 'weight': Munch({'mode': 'lsq_qel_weight', 'bit': 8, 'per_channel': True, 'symmetric': False, 'all_positive': False}), 'excepts': Munch({'g_a.0': Munch({'act': Munch({'bit': 0}), 'weight': Munch({'bit': 8})}), 'h_a.0': Munch({'act': Munch({'all_positive': False}), 'weight': Munch({'bit': 8})}), 'h_s.0': Munch({'act': Munch({'all_positive': False}), 'weight': Munch({'bit': 8})}), 'g_s.0': Munch({'act': Munch({'all_positive': False}), 'weight': Munch({'bit': 8})}), 'g_s.6': Munch({'act': Munch({'bit': 8}), 'weight': Munch({'bit': 8})})})})})
22-11-09 14:45:17.063 - INFO: Namespace(aux_learning_rate=0.001, basepoint='../experiments/MS_q4/checkpoints/checkpoint_best_loss.pth.tar', batch_size=8, checkpoint=None, clip_max_norm=1.0, config='configs/ms_lsqqel.yaml', cuda=True, dataset='/home/qororo606/flicker', epochs=500, experiment='loss_test', gpu_id=0, learning_rate=0.0001, lmbda=0.013, lsq=True, metrics='mse', model='ms-relu', num_workers=4, patch_size=(256, 256), pretrain=False, quality=4, save=True, seed=None, test_batch_size=1)
22-11-09 14:45:17.063 - INFO: MSReLU(
  (entropy_bottleneck): EntropyBottleneck(
    (likelihood_lower_bound): LowerBound()
  )
  (g_a): Sequential(
    (0): QuanConv2d(
      3, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): IdentityQuan()
    )
    (1): ReLU()
    (2): QuanConv2d(
      128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (3): ReLU()
    (4): QuanConv2d(
      128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (5): ReLU()
    (6): QuanConv2d(
      128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
  )
  (g_s): Sequential(
    (0): QuanConvTranspose2d(
      192, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (1): ReLU()
    (2): QuanConvTranspose2d(
      128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (3): ReLU()
    (4): QuanConvTranspose2d(
      128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (5): ReLU()
    (6): QuanConvTranspose2d(
      128, 3, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
  )
  (h_a): Sequential(
    (0): QuanConv2d(
      192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (1): ReLU()
    (2): QuanConv2d(
      128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (3): ReLU()
    (4): QuanConv2d(
      128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
  )
  (h_s): Sequential(
    (0): QuanConvTranspose2d(
      128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (1): ReLU()
    (2): QuanConvTranspose2d(
      192, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
    (3): ReLU()
    (4): QuanConv2d(
      288, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
      (quan_w_fn): LsqQelWeight()
      (quan_a_fn): LsqQelAct()
    )
  )
  (gaussian_conditional): GaussianConditional(
    (likelihood_lower_bound): LowerBound()
    (lower_bound_scale): LowerBound()
  )
)
22-11-09 14:45:17.066 - INFO: Learning rate: 0.0001
22-11-09 14:45:18.017 - INFO: Train epoch 0: [    0/16574 (0%)] RD Loss: 1.7871 | Quant loss: 0.366 | MSE loss: 0.0014 | Bpp loss: 0.6441 | Aux loss: 6.22
22-11-09 14:45:29.505 - INFO: Train epoch 0: [  800/16574 (5%)] RD Loss: 3.1107 | Quant loss: 0.371 | MSE loss: 0.0026 | Bpp loss: 0.8740 | Aux loss: 6.02
22-11-09 14:45:40.650 - INFO: Train epoch 0: [ 1600/16574 (10%)] RD Loss: 2.2691 | Quant loss: 0.339 | MSE loss: 0.0020 | Bpp loss: 0.5696 | Aux loss: 7.00
22-11-09 14:45:51.841 - INFO: Train epoch 0: [ 2400/16574 (14%)] RD Loss: 1.9543 | Quant loss: 0.321 | MSE loss: 0.0017 | Bpp loss: 0.4945 | Aux loss: 5.57
22-11-09 14:46:03.030 - INFO: Train epoch 0: [ 3200/16574 (19%)] RD Loss: 1.9762 | Quant loss: 0.32 | MSE loss: 0.0016 | Bpp loss: 0.6076 | Aux loss: 5.71
22-11-09 14:46:14.263 - INFO: Train epoch 0: [ 4000/16574 (24%)] RD Loss: 1.8099 | Quant loss: 0.306 | MSE loss: 0.0016 | Bpp loss: 0.4629 | Aux loss: 6.18
22-11-09 14:46:25.544 - INFO: Train epoch 0: [ 4800/16574 (29%)] RD Loss: 2.5058 | Quant loss: 0.293 | MSE loss: 0.0025 | Bpp loss: 0.4143 | Aux loss: 5.91
22-11-09 14:46:36.754 - INFO: Train epoch 0: [ 5600/16574 (34%)] RD Loss: 1.7882 | Quant loss: 0.305 | MSE loss: 0.0014 | Bpp loss: 0.5713 | Aux loss: 5.60
22-11-09 14:46:47.733 - INFO: Train epoch 0: [ 6400/16574 (39%)] RD Loss: 1.8709 | Quant loss: 0.294 | MSE loss: 0.0016 | Bpp loss: 0.5324 | Aux loss: 5.59
22-11-09 14:46:58.918 - INFO: Train epoch 0: [ 7200/16574 (43%)] RD Loss: 1.7330 | Quant loss: 0.3 | MSE loss: 0.0013 | Bpp loss: 0.6379 | Aux loss: 5.44
22-11-09 14:47:10.130 - INFO: Train epoch 0: [ 8000/16574 (48%)] RD Loss: 1.4550 | Quant loss: 0.276 | MSE loss: 0.0012 | Bpp loss: 0.4781 | Aux loss: 5.57
22-11-09 14:47:21.187 - INFO: Train epoch 0: [ 8800/16574 (53%)] RD Loss: 2.8563 | Quant loss: 0.295 | MSE loss: 0.0026 | Bpp loss: 0.6361 | Aux loss: 5.79
22-11-09 14:47:32.269 - INFO: Train epoch 0: [ 9600/16574 (58%)] RD Loss: 2.1567 | Quant loss: 0.276 | MSE loss: 0.0020 | Bpp loss: 0.4913 | Aux loss: 5.87
22-11-09 14:47:43.339 - INFO: Train epoch 0: [10400/16574 (63%)] RD Loss: 1.7132 | Quant loss: 0.276 | MSE loss: 0.0013 | Bpp loss: 0.6373 | Aux loss: 5.81
22-11-09 14:47:54.484 - INFO: Train epoch 0: [11200/16574 (68%)] RD Loss: 1.7575 | Quant loss: 0.268 | MSE loss: 0.0014 | Bpp loss: 0.5455 | Aux loss: 5.61
22-11-09 14:48:05.550 - INFO: Train epoch 0: [12000/16574 (72%)] RD Loss: 3.5414 | Quant loss: 0.267 | MSE loss: 0.0037 | Bpp loss: 0.4312 | Aux loss: 5.97
22-11-09 14:48:16.598 - INFO: Train epoch 0: [12800/16574 (77%)] RD Loss: 1.7974 | Quant loss: 0.26 | MSE loss: 0.0014 | Bpp loss: 0.5888 | Aux loss: 6.05
22-11-09 14:48:27.665 - INFO: Train epoch 0: [13600/16574 (82%)] RD Loss: 2.8954 | Quant loss: 0.266 | MSE loss: 0.0028 | Bpp loss: 0.5643 | Aux loss: 6.04
22-11-09 14:48:38.821 - INFO: Train epoch 0: [14400/16574 (87%)] RD Loss: 5.4537 | Quant loss: 0.274 | MSE loss: 0.0059 | Bpp loss: 0.4751 | Aux loss: 5.82
22-11-09 14:48:49.968 - INFO: Train epoch 0: [15200/16574 (92%)] RD Loss: 6.8270 | Quant loss: 0.3 | MSE loss: 0.0071 | Bpp loss: 0.8145 | Aux loss: 5.71
22-11-09 14:49:01.018 - INFO: Train epoch 0: [16000/16574 (97%)] RD Loss: 3.5012 | Quant loss: 0.274 | MSE loss: 0.0033 | Bpp loss: 0.6732 | Aux loss: 6.07
22-11-09 14:51:26.363 - INFO: Learning rate: 0.0001
22-11-09 14:51:26.772 - INFO: Train epoch 1: [    0/16574 (0%)] RD Loss: 6.6576 | Quant loss: 0.277 | MSE loss: 0.0070 | Bpp loss: 0.6992 | Aux loss: 5.52
22-11-09 14:51:38.015 - INFO: Train epoch 1: [  800/16574 (5%)] RD Loss: 6.4921 | Quant loss: 0.263 | MSE loss: 0.0070 | Bpp loss: 0.5642 | Aux loss: 5.66
22-11-09 14:51:49.105 - INFO: Train epoch 1: [ 1600/16574 (10%)] RD Loss: 1.8770 | Quant loss: 0.234 | MSE loss: 0.0017 | Bpp loss: 0.4159 | Aux loss: 6.09
22-11-09 14:52:00.312 - INFO: Train epoch 1: [ 2400/16574 (14%)] RD Loss: 3.1828 | Quant loss: 0.243 | MSE loss: 0.0032 | Bpp loss: 0.5180 | Aux loss: 5.61
22-11-09 14:52:11.525 - INFO: Train epoch 1: [ 3200/16574 (19%)] RD Loss: 5.8105 | Quant loss: 0.265 | MSE loss: 0.0060 | Bpp loss: 0.6995 | Aux loss: 5.52
22-11-09 14:52:22.705 - INFO: Train epoch 1: [ 4000/16574 (24%)] RD Loss: 10.9849 | Quant loss: 0.27 | MSE loss: 0.0124 | Bpp loss: 0.4842 | Aux loss: 5.66
22-11-09 14:52:33.909 - INFO: Train epoch 1: [ 4800/16574 (29%)] RD Loss: 8.8990 | Quant loss: 0.268 | MSE loss: 0.0099 | Bpp loss: 0.5449 | Aux loss: 5.40
22-11-09 14:52:44.882 - INFO: Train epoch 1: [ 5600/16574 (34%)] RD Loss: 6.0192 | Quant loss: 0.259 | MSE loss: 0.0063 | Bpp loss: 0.6931 | Aux loss: 5.26
22-11-09 14:52:55.968 - INFO: Train epoch 1: [ 6400/16574 (39%)] RD Loss: 11.6420 | Quant loss: 0.292 | MSE loss: 0.0127 | Bpp loss: 0.8819 | Aux loss: 5.64
22-11-09 14:53:07.023 - INFO: Train epoch 1: [ 7200/16574 (43%)] RD Loss: 3.1804 | Quant loss: 0.239 | MSE loss: 0.0031 | Bpp loss: 0.5271 | Aux loss: 5.72
22-11-09 14:53:18.170 - INFO: Train epoch 1: [ 8000/16574 (48%)] RD Loss: 6.2470 | Quant loss: 0.264 | MSE loss: 0.0066 | Bpp loss: 0.7003 | Aux loss: 5.71
22-11-09 14:53:29.209 - INFO: Train epoch 1: [ 8800/16574 (53%)] RD Loss: 4.2538 | Quant loss: 0.242 | MSE loss: 0.0043 | Bpp loss: 0.6208 | Aux loss: 6.07
22-11-09 14:53:40.266 - INFO: Train epoch 1: [ 9600/16574 (58%)] RD Loss: 5.4842 | Quant loss: 0.233 | MSE loss: 0.0059 | Bpp loss: 0.4993 | Aux loss: 5.71
22-11-09 14:53:51.393 - INFO: Train epoch 1: [10400/16574 (63%)] RD Loss: 3.2152 | Quant loss: 0.23 | MSE loss: 0.0031 | Bpp loss: 0.5832 | Aux loss: 5.43
